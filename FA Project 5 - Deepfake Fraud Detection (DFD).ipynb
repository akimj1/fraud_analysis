{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2160a351-5645-413e-9da9-2d9cc6477b65",
   "metadata": {
    "id": "2160a351-5645-413e-9da9-2d9cc6477b65"
   },
   "source": [
    "# üò∂‚Äçüå´Ô∏è Project #5: Synthetic Image & Deepfake Fraud Detection\n",
    "*by Andrew Kim - kim.andrew.j1@gmail.com*\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objective\n",
    "\n",
    "Build and evaluate a deepfake fraud detection (DFD) model by using machine learning to examine highly realistic synthetic images generated by models like StyleGAN. \n",
    "\n",
    "Apply computer vision techniques and neural networks to classify facial images as either `real` or `fake`.\n",
    "\n",
    "---\n",
    "\n",
    "## üóÇÔ∏è The Dataset (https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces)\n",
    "The dataset is a simplified version of a real deepfake detection dataset to build and test your model. \n",
    "\n",
    "Dataset includes:\n",
    "- Folder structure:  \n",
    "  - `train/real/`  \n",
    "  - `train/fake/`  \n",
    "- Metadata CSVs:  \n",
    "  - `train.csv`, `valid.csv`, `test.csv`  \n",
    "- Each CSV contains:\n",
    "  - `image_id`  \n",
    "  - `label` (`1 = real`, `0 = fake`)  \n",
    "  - `path` to the image  \n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Project Tasks\n",
    "1. **Image Data Loading & Preprocessing**\n",
    "  - Load image metadata and prepare images using `ImageDataGenerator` or `tf.keras.utils.image_dataset_from_directory`\n",
    "  - Resize to `224x224`, normalize pixel values, and create train/validation splits\n",
    "  - Train the model on the training data and evaluate on the validation/test set\n",
    "\n",
    "2. **Transfer Learning with MobileNetV2**\n",
    "  - Load pretrained MobileNetV2 Model, keeping pre-trained weights fixed\n",
    "  - Fine-tune using deepfake dataset with custom classification\n",
    "  - Implement early stopping and monitor validation performance\n",
    "\n",
    "3. **Custom CNN Architecture**\n",
    "  - Build a basic CNN using `Keras` or `TensorFlow`\n",
    "  - Train on training data and evaluate on validation/test set\n",
    "  - Compare performance against transfer learning approach used in MobileNetV2 Model\n",
    "\n",
    "4. **Model Evaluation & Comparison**\n",
    "  - Report `Accuracy`, `Precision`, `Recall`, `F1-score`, and `ROC-AUC` for all models\n",
    "  - Display `confusion matrices` and analyze performance differences\n",
    "  - Compare CNN to metadata-only baseline using Random Forest on `train.csv` features\n",
    "  - Reflect on image-based vs metadata detection effectiveness and deepfake detection challenges\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2746fc4d-5143-44f3-98d4-3a345e09c3e1",
   "metadata": {
    "id": "2746fc4d-5143-44f3-98d4-3a345e09c3e1"
   },
   "source": [
    "## üóÉÔ∏è Loading and Preparing the Deepfake Image Dataset (https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces)\n",
    "\n",
    "Before building a machine learning model, we need to **load and preprocess** our image data.\n",
    "- Load images from separate folders (`real` and `fake`)\n",
    "- Resize each image to a standard size (`224x224`)\n",
    "- Normalize pixel values to the `[0, 1]` range\n",
    "- Assign class labels (`0 = real`, `1 = fake`)\n",
    "- Combine the images into a unified dataset for modeling\n",
    "\n",
    "This project focuses on model development and evaluation, so the code below loads the complete dataset into memory.\n",
    "\n",
    "Once loaded, the `image arrays (X)` and corresponding `labels (y)` will be ready as training data for any deepfake detection models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b57d8c2-4bd1-4af2-bdd3-4a9f600dc39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Image Data Loading & Preprocessing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found data at: archive/real_vs_fake/real-vs-fake/train/real and archive/real_vs_fake/real-vs-fake/train/fake\n",
      "Real images found: 50000\n",
      "Fake images found: 50000\n",
      "\n",
      "Loading images...\n",
      "Loaded 500 real images\n",
      "Loaded 500 fake images\n",
      "\n",
      "==================================================\n",
      "‚úÖ Dataset successfully loaded!\n",
      "==================================================\n",
      "Image dataset shape: (1000, 224, 224, 3)\n",
      "Label array shape: (1000,)\n",
      "Class distribution: 500 real, 500 fake\n",
      "\n",
      "Training data shape: (800, 224, 224, 3)\n",
      "Testing data shape: (200, 224, 224, 3)\n",
      "Training labels shape: (800,)\n",
      "Testing labels shape: (200,)\n",
      "\n",
      "‚úÖ Image Data Preprocessing complete!\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# IMAGE DATA LOADING & PREPROCESSING\n",
    "# =====================================\n",
    "\n",
    "# Import required libraries\n",
    "import os                        # Used for navigating file directories\n",
    "import numpy as np               # Used for numerical operations and array management\n",
    "from PIL import Image            # Used to open, manipulate, and resize image files\n",
    "import matplotlib.pyplot as plt  # Used for displaying sample images\n",
    "\n",
    "# Import the Markdown function from IPython.display\n",
    "from IPython.display import Markdown\n",
    "display(Markdown(\"## Image Data Loading & Preprocessing\"))\n",
    "\n",
    "# Define file paths relative to the notebook location\n",
    "  # This will work whether the notebook is run locally or from GitHub\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__'))  # Get current directory\n",
    "\n",
    "# Try multiple possible paths to find the data\n",
    "possible_paths = [\n",
    "    # Path 1: Data in same directory as notebook\n",
    "    ('train/real', 'train/fake'),\n",
    "    # Path 2: Data in a subdirectory called 'real-vs-fake'\n",
    "    ('real-vs-fake/train/real', 'real-vs-fake/train/fake'),\n",
    "    # Path 3: Data in archive folder structure\n",
    "    ('archive/real_vs_fake/real-vs-fake/train/real', 'archive/real_vs_fake/real-vs-fake/train/fake'),\n",
    "    # Path 4: Direct real and fake folders\n",
    "    ('real', 'fake'),\n",
    "]\n",
    "\n",
    "# Find which path structure exists\n",
    "real_path = None\n",
    "fake_path = None\n",
    "\n",
    "for real_p, fake_p in possible_paths:\n",
    "    test_real = os.path.join(current_dir, real_p)\n",
    "    test_fake = os.path.join(current_dir, fake_p)\n",
    "    \n",
    "    if os.path.exists(test_real) and os.path.exists(test_fake):\n",
    "        real_path = test_real\n",
    "        fake_path = test_fake\n",
    "        print(f\"Found data at: {real_p} and {fake_p}\")\n",
    "        break\n",
    "\n",
    "# If still not found, check one directory up (in case notebook is in a subfolder)\n",
    "if real_path is None:\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "    for real_p, fake_p in possible_paths:\n",
    "        test_real = os.path.join(parent_dir, real_p)\n",
    "        test_fake = os.path.join(parent_dir, fake_p)\n",
    "        \n",
    "        if os.path.exists(test_real) and os.path.exists(test_fake):\n",
    "            real_path = test_real\n",
    "            fake_path = test_fake\n",
    "            print(f\"Found data at: ../{real_p} and ../{fake_p}\")\n",
    "            break\n",
    "\n",
    "# If still not found, provide helpful error message\n",
    "if real_path is None or fake_path is None:\n",
    "    print(\"‚ùå Error: Could not locate image data!\")\n",
    "    print(\"Please ensure your folder structure is one of the following:\")\n",
    "    print(\"  Option 1: notebook.ipynb, train/real/, train/fake/\")\n",
    "    print(\"  Option 2: notebook.ipynb, real/, fake/\")\n",
    "    print(\"  Option 3: notebook.ipynb, real-vs-fake/train/real/, real-vs-fake/train/fake/\")\n",
    "    print(\"\\nCurrent working directory:\", os.getcwd())\n",
    "    print(\"Files in current directory:\", os.listdir('.'))\n",
    "    raise FileNotFoundError(\"Image data not found. Please check the folder structure.\")\n",
    "else:\n",
    "    print(f\"Real images found: {len(os.listdir(real_path))}\")\n",
    "    print(f\"Fake images found: {len(os.listdir(fake_path))}\")\n",
    "\n",
    "# Define a function to load and preprocess images from a given folder\n",
    "def load_images(folder_path, label, img_size=(224, 224), limit=500):\n",
    "    \"\"\"\n",
    "    Loads images from a folder, resizes them, and assigns a label.\n",
    "    Parameters:\n",
    "        folder_path (str): The path to the image directory\n",
    "        label (int): The class label for the images (0 for real, 1 for fake)\n",
    "        img_size (tuple): Target size to resize images to (width, height)\n",
    "        limit (int): Max number of images to load from the folder\n",
    "    Returns:\n",
    "        images (list): A list of preprocessed image arrays\n",
    "        labels (list): A list of labels corresponding to each image\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Get all image files and shuffle them\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG'))]\n",
    "    \n",
    "    if len(files) == 0:\n",
    "        print(f\"‚ö†Ô∏è Warning: No image files found in {folder_path}\")\n",
    "        return images, labels\n",
    "    \n",
    "    np.random.shuffle(files)\n",
    "    \n",
    "    # Loop through shuffled files\n",
    "    for i, file_name in enumerate(files):\n",
    "        try:\n",
    "            file_path = os.path.join(folder_path, file_name)  # Full file path\n",
    "            img = Image.open(file_path).convert('RGB')        # Open and convert to RGB format\n",
    "            img = img.resize(img_size)                        # Resize image to target size\n",
    "            images.append(np.array(img) / 255.0)              # Normalize pixel values to range [0, 1]\n",
    "            labels.append(label)                              # Assign label to this image\n",
    "            \n",
    "            # Stop loading if the specified limit is reached\n",
    "            if i >= limit - 1:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not load {file_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# Load and label real and fake images using the helper function\n",
    "print(\"\\nLoading images...\")\n",
    "real_images, real_labels = load_images(real_path, label=0)\n",
    "fake_images, fake_labels = load_images(fake_path, label=1)\n",
    "\n",
    "print(f\"Loaded {len(real_images)} real images\")\n",
    "print(f\"Loaded {len(fake_images)} fake images\")\n",
    "\n",
    "# Combine the real and fake datasets into a single dataset\n",
    "X = np.array(real_images + fake_images)  # Feature matrix containing image data\n",
    "y = np.array(real_labels + fake_labels)  # Target labels: 0 for real, 1 for fake\n",
    "\n",
    "# Display the shape of the dataset to confirm it loaded correctly\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"‚úÖ Dataset successfully loaded!\")\n",
    "print(\"=\"*50)\n",
    "print(\"Image dataset shape:\", X.shape)  # Should show (1000, 224, 224, 3)\n",
    "print(\"Label array shape:\", y.shape)\n",
    "print(f\"Class distribution: {np.sum(y==0)} real, {np.sum(y==1)} fake\")\n",
    "\n",
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split  # Used to split dataset into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nTraining data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Testing labels shape: {y_test.shape}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Image Data Preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8a2e2-f1bd-4343-90fa-c19fb6136f69",
   "metadata": {
    "id": "41a915cb-15b9-4d47-a623-2ee779f69dbd"
   },
   "source": [
    "# **Observations - Dataset (https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-face)**\n",
    "- Dataset\n",
    "  - Large (**4 GB**)!\n",
    "    - Selected **`1,000` Images** at random from possible **`140,000` Total Images**\n",
    "      - Then selected **`500` Real** v. **`500` Fake** Images\n",
    "        - Unarchived files & folders saved to HD (*uploaded to Github repository*)\n",
    "    - **Resized** to **`224x224`** pixels to allow for **MobileNetV2/CNN** training (*larger resolution to catch more details*)\n",
    "    - **Training/Testing split** = **`80/20`** (**800 Images for Training/200 Images for Testing**)\n",
    "      - **Image preprocessing:** Normalized pixel values to **`[0,1]`** range; Converted image files to **`RGB` format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8EcG5vDUjluT",
   "metadata": {
    "id": "8EcG5vDUjluT"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## MobileNetV2 Transfer Learning Model"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.12/site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.73.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "\n",
      "TensorFlow version: 2.19.0\n",
      "\n",
      "‚úÖ Model compiled! Total parameters: 2,259,265\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# TRANSFER LEARNING MODEL (MobileNetV2)\n",
    "# =====================================\n",
    "\n",
    "display(Markdown(\"## MobileNetV2 Transfer Learning Model\"))\n",
    "\n",
    "# Install TensorFlow\n",
    "!pip install tensorflow\n",
    "\n",
    "# Then restart kernel and run:\n",
    "import tensorflow as tf\n",
    "print(f\"\\nTensorFlow version: {tf.__version__}\")\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load pre-trained MobileNetV2 (exclude top layer)\n",
    "base_model = MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom classification head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "print(f\"\\n‚úÖ Model compiled! Total parameters: {model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdee1b86-8ae5-4d9b-9e42-8cc9227c12ac",
   "metadata": {},
   "source": [
    "# **Observations - MobileNetV2**\n",
    "- **Transfer Learning Model**\n",
    "  - **MobileNetV2:** *Already trained* in **Image recognition** (**`Google's ImageNet`**) with those learned features kept unchanged (**frozen layers**)\n",
    "    - **`2.259M+` total parameters**\n",
    "    - **Model Configuration:** Uses `Adam optimizer` to *learn from mistakes* and *track success rate* for **`real vs fake`** detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc673f85-448f-4aef-8da0-9b138c4e718b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## MobileNetV2 - Data Preparation & Splitting"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current data shapes:\n",
      "X_train: (800, 224, 224, 3)\n",
      "X_test: (200, 224, 224, 3)\n",
      "Training labels: Real=400, Fake=400\n",
      "Test labels: Real=100, Fake=100\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## MobileNetV2 Model Training"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training transfer learning model...\n",
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 196ms/step - accuracy: 0.5318 - loss: 0.7597 - val_accuracy: 0.6150 - val_loss: 0.6692\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 179ms/step - accuracy: 0.6242 - loss: 0.6475 - val_accuracy: 0.6200 - val_loss: 0.6325\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - accuracy: 0.7126 - loss: 0.5753 - val_accuracy: 0.6450 - val_loss: 0.6182\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - accuracy: 0.7035 - loss: 0.5638 - val_accuracy: 0.6150 - val_loss: 0.6083\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 174ms/step - accuracy: 0.7217 - loss: 0.5239 - val_accuracy: 0.6350 - val_loss: 0.5989\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - accuracy: 0.7522 - loss: 0.5163 - val_accuracy: 0.6500 - val_loss: 0.5977\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - accuracy: 0.7965 - loss: 0.4757 - val_accuracy: 0.6650 - val_loss: 0.5933\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - accuracy: 0.7594 - loss: 0.4840 - val_accuracy: 0.6650 - val_loss: 0.5907\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - accuracy: 0.7769 - loss: 0.4874 - val_accuracy: 0.6900 - val_loss: 0.5912\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - accuracy: 0.7547 - loss: 0.4763 - val_accuracy: 0.6850 - val_loss: 0.5859\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 160ms/step\n",
      "\n",
      "‚úÖ Model training complete!\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# DATA PREPARATION & SPLITTING\n",
    "# =====================================\n",
    "\n",
    "display(Markdown(\"## MobileNetV2 - Data Preparation & Splitting\"))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Your original code created X_train, X_test, y_train, y_test already\n",
    "# But we need to resize images for MobileNetV2 (224x224 instead of 224x224)\n",
    "print(f\"Current data shapes:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "\n",
    "# Images should already be the right size (224, 224, 3) from your original code\n",
    "# If not, you may need to resize them\n",
    "\n",
    "print(f\"Training labels: Real={np.sum(y_train==1)}, Fake={np.sum(y_train==0)}\")\n",
    "print(f\"Test labels: Real={np.sum(y_test==1)}, Fake={np.sum(y_test==0)}\")\n",
    "\n",
    "# =====================================\n",
    "# MODEL TRAINING & HYPERPARAMETER TUNING\n",
    "# =====================================\n",
    "\n",
    "display(Markdown(\"## MobileNetV2 Model Training\"))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "print(\"\\nTraining transfer learning model...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "print(\"\\n‚úÖ Model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4315417c-3153-4d0d-a840-f8a4d99301a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# **Observations - MobileNetV2 Model Training**\n",
       "- **Data Verification**\n",
       "  - **Training set:** **`800`** images (224x224x3), *balanced* **`400`** real/**`400`** fake\n",
       "  - **Test set:** **`200`** images (224x224x3), *balanced* **`100`** real/**`100`** fake\n",
       "  - Images *already properly sized* for MobileNetV2 (**`224x224` pixels**)\n",
       "- **Training Configuration**\n",
       "  - **10 Epochs max:** **Prevents overfitting** while allowing *sufficient learning time* for transfer learning\n",
       "    - **Insight:** *Less* **memorization**, *More* **learning** \n",
       "  - **Batch Size** = **`32`**: Balances memory efficiency with stable gradient updates (**`800/32`** = **`25`** Batches per Epoch)\n",
       "    - **Insight:** Better to update learning after 10+ but less than 50 \n",
       "  - **`early_stopping`:** Automatically **halts training** *if* validation loss *stops improving* for **3 consecutive** Epochs\n",
       "    - **Insight:** Model Training **continued to improve** until Max Epoch reached \n",
       "- **Training Results**\n",
       "  - Model *completed* all **`10` Epochs** *without* early stoppage\n",
       "  - **Final Validation Accuracy (**`val_accuracy`**):** 68.5%\n",
       "    - **Insight:** Training showed *steady improvement* from 61.5% to 68.5% Validation Accuracy\n",
       "  - **Final Validation Loss (**`val_loss`**):** 0.586\n",
       "    - **Insight:** Validation *loss decreased* from 0.669 to 0.586 indicating **effective learning**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Extract dynamic values from training history\n",
    "final_val_accuracy = history.history['val_accuracy'][-1]\n",
    "initial_val_accuracy = history.history['val_accuracy'][0]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "initial_val_loss = history.history['val_loss'][0]\n",
    "\n",
    "markdown_content = f\"\"\"\n",
    "# **Observations - MobileNetV2 Model Training**\n",
    "- **Data Verification**\n",
    "  - **Training set:** **`800`** images (224x224x3), *balanced* **`400`** real/**`400`** fake\n",
    "  - **Test set:** **`200`** images (224x224x3), *balanced* **`100`** real/**`100`** fake\n",
    "  - Images *already properly sized* for MobileNetV2 (**`224x224` pixels**)\n",
    "- **Training Configuration**\n",
    "  - **10 Epochs max:** **Prevents overfitting** while allowing *sufficient learning time* for transfer learning\n",
    "    - **Insight:** *Less* **memorization**, *More* **learning** \n",
    "  - **Batch Size** = **`32`**: Balances memory efficiency with stable gradient updates (**`800/32`** = **`25`** Batches per Epoch)\n",
    "    - **Insight:** Better to update learning after 10+ but less than 50 \n",
    "  - **`early_stopping`:** Automatically **halts training** *if* validation loss *stops improving* for **3 consecutive** Epochs\n",
    "    - **Insight:** Model Training **continued to improve** until Max Epoch reached \n",
    "- **Training Results**\n",
    "  - Model *completed* all **`10` Epochs** *without* early stoppage\n",
    "  - **Final Validation Accuracy (**`val_accuracy`**):** {final_val_accuracy:.1%}\n",
    "    - **Insight:** Training showed *steady improvement* from {initial_val_accuracy:.1%} to {final_val_accuracy:.1%} Validation Accuracy\n",
    "  - **Final Validation Loss (**`val_loss`**):** {final_val_loss:.3f}\n",
    "    - **Insight:** Validation *loss decreased* from {initial_val_loss:.3f} to {final_val_loss:.3f} indicating **effective learning**\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(markdown_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f5aa834-9b61-4979-afc9-e0c2a0819d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## MobileNetV2 Model Evaluation & Visualization"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TRANSFER LEARNING RESULTS\n",
      "==================================================\n",
      "Precision: 0.683\n",
      "Recall: 0.690\n",
      "F1-Score: 0.687\n",
      "ROC-AUC: 0.762\n",
      "\n",
      "Confusion Matrix:\n",
      "[[68 32]\n",
      " [31 69]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.69      0.68      0.68       100\n",
      "        Fake       0.68      0.69      0.69       100\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.69      0.69      0.68       200\n",
      "weighted avg       0.69      0.69      0.68       200\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# MODEL EVALUATION\n",
    "# =====================================\n",
    "\n",
    "# Import Markdown\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "display(Markdown(\"## MobileNetV2 Model Evaluation & Visualization\"))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRANSFER LEARNING RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1-Score: {f1:.3f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.3f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Real', 'Fake']))\n",
    "\n",
    "# Simple visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "metrics = ['Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "values = [precision, recall, f1, roc_auc]\n",
    "plt.bar(metrics, values, color=['skyblue', 'lightcoral', 'lightgreen', 'gold'])\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Model Performance')\n",
    "plt.ylabel('Score')\n",
    "for i, v in enumerate(values):\n",
    "    plt.text(i, v + 0.01, f'{v:.3f}', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Model evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfc05699-9c32-4eab-84b1-699857613a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Convolutional Neural Network (CNN)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN...\n",
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 444ms/step - accuracy: 0.4754 - loss: 1.5181 - val_accuracy: 0.5550 - val_loss: 0.6927\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 476ms/step - accuracy: 0.5500 - loss: 0.6924 - val_accuracy: 0.6150 - val_loss: 0.6835\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 482ms/step - accuracy: 0.6245 - loss: 0.6642 - val_accuracy: 0.6250 - val_loss: 0.6606\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 482ms/step - accuracy: 0.6711 - loss: 0.6185 - val_accuracy: 0.6200 - val_loss: 0.7029\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 481ms/step - accuracy: 0.7244 - loss: 0.5662 - val_accuracy: 0.5900 - val_loss: 0.7448\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 507ms/step - accuracy: 0.7571 - loss: 0.5073 - val_accuracy: 0.6250 - val_loss: 0.7511\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 496ms/step - accuracy: 0.8565 - loss: 0.3715 - val_accuracy: 0.6550 - val_loss: 0.9516\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 493ms/step - accuracy: 0.8881 - loss: 0.2671 - val_accuracy: 0.6050 - val_loss: 0.9545\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 474ms/step - accuracy: 0.9058 - loss: 0.2301 - val_accuracy: 0.6500 - val_loss: 1.2223\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 476ms/step - accuracy: 0.9541 - loss: 0.1318 - val_accuracy: 0.6450 - val_loss: 1.1612\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step\n",
      "\n",
      "CNN RESULTS\n",
      "====================\n",
      "Precision: 0.612\n",
      "Recall: 0.790\n",
      "F1-Score: 0.690\n",
      "ROC-AUC: 0.695\n",
      "\n",
      "Confusion Matrix:\n",
      "[[50 50]\n",
      " [21 79]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.70      0.50      0.58       100\n",
      "        Real       0.61      0.79      0.69       100\n",
      "\n",
      "    accuracy                           0.65       200\n",
      "   macro avg       0.66      0.65      0.64       200\n",
      "weighted avg       0.66      0.65      0.64       200\n",
      "\n",
      "\n",
      "‚úÖ Model training complete!\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# CNN MODEL\n",
    "# =====================================\n",
    "\n",
    "display(Markdown(\"## Convolutional Neural Network (CNN)\"))\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Build basic CNN with Input layer\n",
    "cnn_model = Sequential([\n",
    "    Input(shape=(224, 224, 3)),  # Add Input layer first\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')])\n",
    "\n",
    "cnn_model.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train CNN\n",
    "print(\"Training CNN...\")\n",
    "history = cnn_model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "                   epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate CNN\n",
    "y_pred_proba = cnn_model.predict(X_test)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"\\nCNN RESULTS\")\n",
    "print(\"=\"*20)\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1-Score: {f1:.3f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.3f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "print()\n",
    "print(classification_report(y_test, y_pred, target_names=['Fake', 'Real']))\n",
    "\n",
    "print(\"\\n‚úÖ Model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b7f45a1-d4fc-4403-a107-511fbe180f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# **Observations - CNN Model Training Process**\n",
       "- **Data Verification**\n",
       "  - **Training set:** **`800`** images (224x224x3), *balanced* **`400`** real/**`400`** fake\n",
       "  - **Test set:** **`200`** images (224x224x3), *balanced* **`100`** real/**`100`** fake\n",
       "  - Images *already properly sized* for CNN Model (224x224 pixels)\n",
       "- **Training Configuration**\n",
       "  - **10 Epochs max:** Full training duration *without* **early stopping**\n",
       "    - **Insight:** *Less* **memorization**, *More* **learning** \n",
       "    - **Insight:** Model trained through **complete** Epoch cycle\n",
       "  - **Batch Size** = **`32`**: Balances memory efficiency with stable gradient updates (**`800/32`** = **`25`** Batches per Epoch)\n",
       "    - **Insight:** Better to update learning after 10+ but less than 50 \n",
       "    - **Insight:** Standard batch size for image classification tasks\n",
       "- **Custom CNN Architecture:** **`3`** Conv layers (`32‚Üí64‚Üí128` filters) + Dense(`512`) + Dropout(`0.5`)\n",
       "  - **Insight:** Progressive feature extraction from basic to complex patterns\n",
       "- **Training Results**\n",
       "  - Model *completed* all **`10` Epochs**\n",
       "  - **Final Validation Accuracy (**`val_accuracy`**):** 64.5%\n",
       "    - **Insight:** Validation accuracy *improved* from 55.5% to 64.5%, showing improving detection\n",
       "  - **Final Validation Loss (**`val_loss`**):** 1.161\n",
       "    - **Insight:** Validation *loss increased* from 0.693 to 1.161 indicating **distressing predictions**\n",
       "  - **Insight:** *Improved detection* but **increased uncertainty** in flagging Fake images, meaning CNN Model is **not learning** and is **instead memorizing** patterns\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Extract dynamic values from CNN training history\n",
    "final_val_accuracy = history.history['val_accuracy'][-1]\n",
    "initial_val_accuracy = history.history['val_accuracy'][0]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "initial_val_loss = history.history['val_loss'][0]\n",
    "\n",
    "# Determine if loss improved or worsened\n",
    "loss_direction = \"decreased\" if final_val_loss < initial_val_loss else \"increased\"\n",
    "\n",
    "markdown_content = f\"\"\"\n",
    "# **Observations - CNN Model Training Process**\n",
    "- **Data Verification**\n",
    "  - **Training set:** **`800`** images (224x224x3), *balanced* **`400`** real/**`400`** fake\n",
    "  - **Test set:** **`200`** images (224x224x3), *balanced* **`100`** real/**`100`** fake\n",
    "  - Images *already properly sized* for CNN Model (224x224 pixels)\n",
    "- **Training Configuration**\n",
    "  - **10 Epochs max:** Full training duration *without* **early stopping**\n",
    "    - **Insight:** *Less* **memorization**, *More* **learning** \n",
    "    - **Insight:** Model trained through **complete** Epoch cycle\n",
    "  - **Batch Size** = **`32`**: Balances memory efficiency with stable gradient updates (**`800/32`** = **`25`** Batches per Epoch)\n",
    "    - **Insight:** Better to update learning after 10+ but less than 50 \n",
    "    - **Insight:** Standard batch size for image classification tasks\n",
    "- **Custom CNN Architecture:** **`3`** Conv layers (`32‚Üí64‚Üí128` filters) + Dense(`512`) + Dropout(`0.5`)\n",
    "  - **Insight:** Progressive feature extraction from basic to complex patterns\n",
    "- **Training Results**\n",
    "  - Model *completed* all **`10` Epochs**\n",
    "  - **Final Validation Accuracy (**`val_accuracy`**):** {final_val_accuracy:.1%}\n",
    "    - **Insight:** Validation accuracy *improved* from {initial_val_accuracy:.1%} to {final_val_accuracy:.1%}, showing improving detection\n",
    "  - **Final Validation Loss (**`val_loss`**):** {final_val_loss:.3f}\n",
    "    - **Insight:** Validation *loss {loss_direction}* from {initial_val_loss:.3f} to {final_val_loss:.3f} indicating **distressing predictions**\n",
    "  - **Insight:** *Improved detection* but **increased uncertainty** in flagging Fake images, meaning CNN Model is **not learning** and is **instead memorizing** patterns\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(markdown_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "753759a5-a902-4744-87bf-3ecf9856a593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Metadata-Only v. CNN Model Comparison"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found train.csv at: archive/train.csv\n",
      "CSV shape: (100000, 6)\n",
      "Columns: ['Unnamed: 0', 'original_path', 'id', 'label', 'label_str', 'path']\n",
      "\n",
      "   Unnamed: 0                                      original_path     id  \\\n",
      "0           0  /kaggle/input/flickrfaceshq-dataset-nvidia-par...  31355   \n",
      "1           1  /kaggle/input/flickrfaceshq-dataset-nvidia-par...  02884   \n",
      "2           2  /kaggle/input/flickrfaceshq-dataset-nvidia-par...  33988   \n",
      "3           3  /kaggle/input/flickrfaceshq-dataset-nvidia-par...  53875   \n",
      "4           4  /kaggle/input/flickrfaceshq-dataset-nvidia-par...  24149   \n",
      "\n",
      "   label label_str                  path  \n",
      "0      1      real  train/real/31355.jpg  \n",
      "1      1      real  train/real/02884.jpg  \n",
      "2      1      real  train/real/33988.jpg  \n",
      "3      1      real  train/real/53875.jpg  \n",
      "4      1      real  train/real/24149.jpg  \n",
      "\n",
      "Metadata features shape: (100000, 3)\n",
      "Feature columns: ['filename_length', 'has_numbers', 'file_extension_encoded']\n",
      "\n",
      "Metadata vs Image Model Comparison\n",
      "=============================================\n",
      "Image-based CNN ROC-AUC: 0.695\n",
      "Metadata-only RF ROC-AUC: 1.000\n",
      "Better performer: Metadata\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# METADATA-ONLY v. CNN MODEL COMPARISON\n",
    "# =====================================\n",
    "\n",
    "display(Markdown(\"## Metadata-Only v. CNN Model Comparison\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Calculate CNN ROC-AUC if needed\n",
    "if 'roc_auc' not in locals():\n",
    "    # Check which model exists and calculate ROC-AUC\n",
    "    if 'model' in locals():  # Transfer learning model\n",
    "        y_pred_proba_cnn = model.predict(X_test).flatten()\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba_cnn)\n",
    "        print(f\"Calculated CNN ROC-AUC: {roc_auc:.3f}\")\n",
    "    elif 'custom_model' in locals():  # Custom CNN\n",
    "        y_pred_proba_cnn = custom_model.predict(X_test).flatten()\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba_cnn)\n",
    "        print(f\"Calculated Custom CNN ROC-AUC: {roc_auc:.3f}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Warning: No CNN model found. Using default value.\")\n",
    "        roc_auc = 0.5  # Default baseline\n",
    "        \n",
    "# Load metadata CSV - try multiple possible locations\n",
    "possible_csv_paths = [\n",
    "    'train.csv',  # Same directory as notebook\n",
    "    'archive/train.csv',  # In archive folder\n",
    "    '../train.csv',  # One directory up\n",
    "    'data/train.csv',  # In data subfolder\n",
    "]\n",
    "\n",
    "train_df = None\n",
    "for csv_path in possible_csv_paths:\n",
    "    if os.path.exists(csv_path):\n",
    "        train_df = pd.read_csv(csv_path)\n",
    "        print(f\"Found train.csv at: {csv_path}\")\n",
    "        break\n",
    "\n",
    "# If not found in common locations, check parent directories\n",
    "if train_df is None:\n",
    "    parent_dir = os.path.dirname(os.getcwd())\n",
    "    for csv_path in possible_csv_paths:\n",
    "        full_path = os.path.join(parent_dir, csv_path)\n",
    "        if os.path.exists(full_path):\n",
    "            train_df = pd.read_csv(full_path)\n",
    "            print(f\"Found train.csv at: {full_path}\")\n",
    "            break\n",
    "\n",
    "# If still not found, provide helpful error\n",
    "if train_df is None:\n",
    "    print(\"‚ùå Error: Could not locate train.csv!\")\n",
    "    print(\"Please ensure train.csv is in one of these locations:\")\n",
    "    print(\"  - Same folder as this notebook\")\n",
    "    print(\"  - In an 'archive' subfolder\")\n",
    "    print(\"  - In a 'data' subfolder\")\n",
    "    print(\"\\nSkipping metadata comparison...\")\n",
    "else:\n",
    "    print(f\"CSV shape: {train_df.shape}\")\n",
    "    print(f\"Columns: {train_df.columns.tolist()}\")\n",
    "    print()\n",
    "    print(train_df.head())\n",
    "\n",
    "    # Create numeric features from metadata (no image data)\n",
    "    metadata_features = pd.DataFrame()\n",
    "\n",
    "    # Extract features from file paths/names\n",
    "    if 'path' in train_df.columns:\n",
    "        metadata_features['filename_length'] = train_df['path'].str.len()\n",
    "        metadata_features['has_numbers'] = train_df['path'].str.contains(r'\\d').astype(int)\n",
    "        metadata_features['file_extension'] = train_df['path'].str.split('.').str[-1]\n",
    "        \n",
    "        # Encode file extension\n",
    "        le = LabelEncoder()\n",
    "        metadata_features['file_extension_encoded'] = le.fit_transform(metadata_features['file_extension'])\n",
    "        metadata_features = metadata_features.drop('file_extension', axis=1)\n",
    "\n",
    "    # If image_id exists, create features from it\n",
    "    if 'image_id' in train_df.columns:\n",
    "        metadata_features['id_length'] = train_df['image_id'].astype(str).str.len()\n",
    "\n",
    "    # Ensure we have some features\n",
    "    if metadata_features.empty:\n",
    "        # Create simple index-based features as fallback\n",
    "        metadata_features['row_index'] = range(len(train_df))\n",
    "        metadata_features['label_encoded'] = train_df['label']\n",
    "\n",
    "    print(f\"\\nMetadata features shape: {metadata_features.shape}\")\n",
    "    print(f\"Feature columns: {metadata_features.columns.tolist()}\")\n",
    "\n",
    "    # Sample same size as image dataset (1000)\n",
    "    sample_size = min(1000, len(train_df))\n",
    "    sample_indices = np.random.choice(len(train_df), size=sample_size, replace=False)\n",
    "\n",
    "    X_metadata = metadata_features.iloc[sample_indices]\n",
    "    y_metadata = train_df['label'].iloc[sample_indices]\n",
    "\n",
    "    # Split metadata\n",
    "    X_meta_train, X_meta_test, y_meta_train, y_meta_test = train_test_split(\n",
    "        X_metadata, y_metadata, test_size=0.2, random_state=42, stratify=y_metadata)\n",
    "\n",
    "    # Train Random Forest classifier\n",
    "    rf_metadata = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_metadata.fit(X_meta_train, y_meta_train)\n",
    "\n",
    "    # Evaluate metadata model\n",
    "    meta_auc = roc_auc_score(y_meta_test, rf_metadata.predict_proba(X_meta_test)[:, 1])\n",
    "\n",
    "    # Compare models\n",
    "    print(\"\\nMetadata vs Image Model Comparison\")\n",
    "    print(\"=\"*45)\n",
    "    print(f\"Image-based CNN ROC-AUC: {roc_auc:.3f}\")\n",
    "    print(f\"Metadata-only RF ROC-AUC: {meta_auc:.3f}\")\n",
    "    print(f\"Better performer: {'CNN' if roc_auc > meta_auc else 'Metadata'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c705f29-8fc9-4cc3-beed-5f3afe455cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# **Observations - Metadata-Only Model vs Image-Based Models (MobileNetV2; CNN)**\n",
       "- **Metadata Feature Engineering**\n",
       "  - **Extracted features from file paths:** `filename length`, `presence of numbers`, `file extension`\n",
       "  - Used **Random Forest Classifier** with **`100`** estimators\n",
       "  - Same dataset split (**`800` train/`200` test**) for *fair* comparison\n",
       "  - Features based on **file metadata** rather than **actual image content**\n",
       "- **Metadata Model Performance**\n",
       "  - **`Random Forest ROC-AUC:`** 1.000\n",
       "  - Training on filename patterns and file characteristics only\n",
       "    - **Insight:** *Suspiciously* **high performance** suggests Dataset **file naming patterns** accidentally **reveal** the answers (*either by Fraudsters or Dataset Researchers*)\n",
       "- **Model Comparison Results**\n",
       "  - **`CNN from Scratch ROC-AUC:`** 0.695\n",
       "  - **`Metadata-only RF ROC-AUC:`** 1.000\n",
       "  - **`Better performer:`** Metadata\n",
       "- **Key Insights - CNN vs MobileNetV2 vs Metadata:**\n",
       "  - **CNN Learning Limitation:** CNN Model *struggled* with feature extraction from scratch, achieving **moderate performance** but showing *overfitting behavior* \n",
       "    - **Insight:** CNN Model **improving accuracy** but with *worsening* **loss**\n",
       "  - **Transfer Learning Advantage:** MobileNetV2 *leveraged* pre-trained ImageNet features for **superior Deepfake detection**\n",
       "    - **Insight:** MobileNetV2 Model *completed training* in **half the time** it took CNN Model\n",
       "    - **Insight:** Established visual pattern recognition (MobileNetV2) > Building from scratch (CNN)\n",
       "  - **Metadata Anomaly:** *Perfect/near-perfect* Metadata performance likely indicates *easily identifiable Dataset patterns* rather than any *real* accuracy\n",
       "    - **Insight:** While Metadata *could be useful* in detection, **more complex Datasets** could *fool* models strictly using Metadata instead of real training\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Extract metadata model performance\n",
    "# meta_auc should be available from the metadata model evaluation\n",
    "# roc_auc should be available from the CNN model evaluation\n",
    "\n",
    "markdown_content = f\"\"\"\n",
    "# **Observations - Metadata-Only Model vs Image-Based Models (MobileNetV2; CNN)**\n",
    "- **Metadata Feature Engineering**\n",
    "  - **Extracted features from file paths:** `filename length`, `presence of numbers`, `file extension`\n",
    "  - Used **Random Forest Classifier** with **`100`** estimators\n",
    "  - Same dataset split (**`800` train/`200` test**) for *fair* comparison\n",
    "  - Features based on **file metadata** rather than **actual image content**\n",
    "- **Metadata Model Performance**\n",
    "  - **`Random Forest ROC-AUC:`** {meta_auc:.3f}\n",
    "  - Training on filename patterns and file characteristics only\n",
    "    - **Insight:** *Suspiciously* **high performance** suggests Dataset **file naming patterns** accidentally **reveal** the answers (*either by Fraudsters or Dataset Researchers*)\n",
    "- **Model Comparison Results**\n",
    "  - **`CNN from Scratch ROC-AUC:`** {roc_auc:.3f}\n",
    "  - **`Metadata-only RF ROC-AUC:`** {meta_auc:.3f}\n",
    "  - **`Better performer:`** {'CNN' if roc_auc > meta_auc else 'Metadata'}\n",
    "- **Key Insights - CNN vs MobileNetV2 vs Metadata:**\n",
    "  - **CNN Learning Limitation:** CNN Model *struggled* with feature extraction from scratch, achieving **moderate performance** but showing *overfitting behavior* \n",
    "    - **Insight:** CNN Model **improving accuracy** but with *worsening* **loss**\n",
    "  - **Transfer Learning Advantage:** MobileNetV2 *leveraged* pre-trained ImageNet features for **superior Deepfake detection**\n",
    "    - **Insight:** MobileNetV2 Model *completed training* in **half the time** it took CNN Model\n",
    "    - **Insight:** Established visual pattern recognition (MobileNetV2) > Building from scratch (CNN)\n",
    "  - **Metadata Anomaly:** *Perfect/near-perfect* Metadata performance likely indicates *easily identifiable Dataset patterns* rather than any *real* accuracy\n",
    "    - **Insight:** While Metadata *could be useful* in detection, **more complex Datasets** could *fool* models strictly using Metadata instead of real training\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(markdown_content))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
